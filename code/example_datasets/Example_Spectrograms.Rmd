---
title: <center style="font-size:30px;font-style:normal;color:#0E0E7D;">Generate spectrogram image files for example datasets</center>
author: |
  <br />
  <center style="font-style:normal;">
  <a style="font-size:22px;color:#337ab7;text-decoration: underline;"href="https://brittanycoppinger.weebly.com/">Brittany A. Coppinger</a><sup><span style="font-size:12px;color:black;text-decoration:none!important;">1,3</span></sup>,
  <a style="font-size:22px;color:#337ab7;text-decoration: underline;"href="https://smith-vidaurrelab.github.io/">Grace Smith-Vidaurre</a><sup><span style="font-size:12px;color:black;text-decoration:none!important;">1-3*</span></sup>
  <br />
  <br />
  <center style="font-size:18px;font-style:normal;color:black;"><sup><span style="font-size:12px;color:black;">1</span></sup>Department of Integrative Biology, Michigan State University</center>
  <center style="font-size:18px;font-style:normal;color:black;"><sup><span style="font-size:12px;color:black;">2</span></sup>Department of Computational Mathematics, Science, and Engineering, Michigan State University</center>
  <center style="font-size:18px;font-style:normal;color:black;"><sup><span style="font-size:12px;color:black;">3</span></sup>Ecology, Evolution, and Behavior Program, Michigan State University</center>
  <br />
  <center style="font-size:18px;"><sup style="font-size:12px;">*</sup>Corresponding author (smithvid@msu.edu)</center>
date: <center style=font-size:22px;font-style:normal;>`r format(Sys.time(), '%d %B %Y')`</center>
  <br />
output: 
  html_document:
    toc: true
    toc_depth: 4
    toc_float:
      collapsed: false
---

<style type="text/css">
body{
  font-family: Arial;
  font-size: 14pt;
}
h1{
  font-size: 22pt;
}

h2{
  font-size: 18pt;
}

h3{
  font-size: 16pt;
}
</style>

**Purpose**: Here we generate spectrogram image files for two synthetic datasets of vocal identity signals. One data set, the 
"group-specific" dataset has twice the amount of group information encoded as individual information. The other dataset, the "individually distinctive" dataset has twice the amount of individual information encoded as group information. We select a sub-sample of of each of these datasets for visualization (Figs 2 and 3 in the manuscript), and this code allows for resizing and adding colored borders to those selected spectrograms. These selected spectrograms are used in inkscape to create Figs 2 and 3. 

For this script to work, you will need to either run the script `Generate_SyntheticDatasets.Rmd` to create the synthetic vocal identity signals, OR you will need to access files we have already created that are stored in a shared location. If you want to reproduce the same results, then we recommend using the files stored in a shared location.

```{r setup, include = FALSE}

knitr::opts_chunk$set(echo = TRUE, eval = TRUE, warning = FALSE, messsage = FALSE, root.dir = "~/Desktop")

```

Load packages and set cores
```{r}

# Clean the global environment
rm(list = ls())

# Specify the required packages
X <- c("tidyverse", "pbapply", "warbleR", "paletteer")

# Install the packages in X if not already installed
is_installed <- function(p) is.element(p, installed.packages()[,1])

invisible(lapply(1:length(X), function(x){
  if(!is_installed(X[x])){
    install.packages(X[x], repos = "http://lib.stat.cmu.edu/R/CRAN")
  }
}))

cores <- parallel::detectCores() - 4
cores

```

```{r load packages, eval = FALSE}

# Load all of the packages specified above
invisible(lapply(X, library, character.only = TRUE, verbose = FALSE))

```

```{r load packages in background, include = FALSE}

# The only solution right now to avoid having a whole bunch of verbose output printed from the chunk above
# Load all of the packages specified above
invisible(lapply(X, library, character.only = TRUE, verbose = FALSE))

```

Initialize working directories for data on your local machine.
```{r}

###################### Manually update in every new coding session ##################################

# Initialize a base path (this will need to be different per user)
# path <- "/Users/raneemsamman/Desktop" # Raneem's path
# path <- "/Users/gracesmith-vidaurre/Desktop" # Grace's path
path <- "/Users/gsvidaurre/Desktop" # Grace's path
# path <- "C:/Users/britt/Desktop" # Brittany's path

# Initialize a path for the local GitHub repo for this manuscript, for saving final figures here
# git_path <- "C:/Users/britt/Documents/GitHub/paRsynth-methods-paper-internal/figures" # Britt's path
git_path <- file.path("/Users/gsvidaurre/Desktop/GitHub_repos") # Grace's path

```

```{r}

# Initialize the directory for analysis on your local computer
analysis_dir <- "paRsynth_methods_synthetic_dataset"

# Combine the base path and the data directory into a single path
analysis_path <- file.path(path, analysis_dir)

# Create the data directory if it doesn't already exist on your computer
if(!dir.exists(analysis_path)){ 
  dir.create(analysis_path)
}

# Specify a folder inside the analysis directory where audio will be written out/read in
audio_dir <- "audio"

# Combine the base path, the analysis directory, and the audio directory into a single path
audio_path <- file.path(path, analysis_dir, audio_dir)

# Create the audio directory if it doesn't already exist on your computer
if(!dir.exists(audio_path)){ 
  dir.create(audio_path)
}

# Specify a folder inside the analysis directory where images will be written out/read in
images_dir <- "images"

# Combine the base path, the analysis directory, and the data directory into a single path
images_path <- file.path(path, analysis_dir, images_dir)

# Create the data directory if it doesn't already exist on your computer
if(!dir.exists(images_path)){ 
  dir.create(images_path)
}

# Specify a folder inside the analysis directory where images for figures will be written out/read in
figures_dir <- "figures"

# Combine the base path, the analysis directory, and the data directory into a single path
figures_path <- file.path(path, analysis_dir, figures_dir)

# Create the data directory if it doesn't already exist on your computer
if(!dir.exists(figures_path)){ 
  dir.create(figures_path)
}

# Create new path that will hold audio files selected for spectrogram lexicons in manuscript figures
lexicon_path <- file.path(audio_path, "LexiconFigureFiles")

# Create the directory if it doesn't already exist on your computer
if(!dir.exists(lexicon_path)){ 
  dir.create(lexicon_path)
}

# Audio files for generating spectrograms for lexicons should be manually copied into the folder above

```

Read in the synthetic call metadata.
```{r}

synthetic_call_metadata <- read.csv(file.path(analysis_path, "synthetic_call_metadata.csv"))

glimpse(synthetic_call_metadata)

```

# Step 1: Create a warbleR selection table
```{r}

# Create a vector of all of the audio files in the analysis path
wavs <- list.files(path = audio_path, pattern = ".wav$", full.names = FALSE)

# Double check that the number of files is correct (looks good)
length(wavs)

# Double check the formatting of files names that were read it. 
head(wavs)

# Iterate over the audio files to create one row of the selection table at a time. warbleR selection tables have a very specific format that must be used for downstream analysis.
sel_tbl <- data.table::rbindlist(pblapply(1:length(wavs), function(w){
  
  tmp <- tuneR::readWave(file.path(audio_path, wavs[w]))
  
  # Return the metadata for the given call using the synthetic metadata generated during audio file generation above
  metadats_tmp <- synthetic_call_metadata %>%
    dplyr::filter(grepl(wavs[w], audio_file_name))
  
  # Create a row for the selection table in warbleR format if the audio file exists and metadata for that file also exists
  if(nrow(metadats_tmp) > 0){
    
    # Use 0.1s as a margin to indicate where the vocalization starts and ends in the audio file
    # soundgen::soundgen() adds 100ms of silence before and after the synthetic vocalization by default 
    res <- data.frame(
      sound.files = wavs[w], 
      selec = 1,
      start = 0.1, 
      end = seewave::duration(tmp) - 0.1,
      sampling_rate = tmp@samp.rate,
      group_ID = metadats_tmp[["Group"]],
      individual_ID = metadats_tmp[["Individual"]],
      call = metadats_tmp[["Call"]],
      call_ID = metadats_tmp[["Call_ID"]]
    )
    
  } else {
    
    res <- data.frame(
      sound.files = wavs[w], 
      selec = 1, 
      start = 0.1, 
      end = seewave::duration(tmp) + 0.1,
      sampling_rate = NA,
      group_ID = NA,
      individual_ID = NA,
      call = NA,
      call_ID = NA
    )
    
  }
  
  return(res)
  
}))

# See the selection table in warbleR format with all useful metadata for the synthetic experiment
glimpse(sel_tbl)

# Looks good, a single sampling rate across files
unique(sel_tbl$sampling_rate)

```

# Step 2: Create spectrogram image files of each audio file
```{r eval = FALSE}

warbleR::spectrograms(sel_tbl, wl = 512, flim = c(0, 12), wn = "hanning", pal = reverse.gray.colors.2,ovlp = 90, inner.mar = c(5, 4, 4, 2), outer.mar = c(0, 0, 0, 0), picsize = 1, res = 100, cexlab = 1, propwidth = FALSE, xl = 1, osci = FALSE, gr = FALSE, sc = FALSE, line = FALSE, mar = 0.05, it = "jpeg", parallel = 1, path = audio_path, pb = TRUE, fast.spec = FALSE, by.song = NULL, sel.labels = NULL, title.labels = NULL, dest.path = images_path, box = TRUE, axis = TRUE)

# Rename the image files to remove the -1 appended after the extension
imgs <- list.files(images_path)
imgs

new_nms <- gsub(".wav-1", "", imgs)
new_nms

invisible(file.rename(file.path(images_path, imgs), file.path(images_path, new_nms)))

```

# Step 3: Manually upload the original image files to a shared location

The image files were uploaded to a shared Google Drive folder that also contains the audio files.


# Step 4: Select Spectrograms to use, read them

We selected files that match the groups chosen for the acoustic space plots. 

For the "group-specific" dataset, we choose 2 calls from 2 individuals from Group 2 and Group 3

Group 2: Individual 4 (calls 1 and 2), Individual 6 (calls 1 and 2)
Group 3: Individual 1 (calls 3 and 4), Individual 4 (calls 1 and 4)

For the "individually distinctive" dataset, we choose 2 calls from 2 individuals from Group 1 and Group 2

Group 1: Individual 1 (calls 2 and 3), Individual 3 (calls 1 and 2)
Group 2: Individual 1 (calls 3 and 5), Individual 2 (calls 1 and 2)

Make sure to move these selected spectrogram files to the "lexicon" folder in the working directory before proceeding with the following steps in this code. 


# Step 5: Read the spectrogram image files back in for resizing to make publication quality

Before you create this figure, you will need to copy the selected audio files to be used in lexicon figures to the folder generated above that should hold lexicon audio files. After having done that, you can set the path to this folder and read in all these files, as below.
```{r eval=FALSE}

# First, read in audio files of selected calls, moved to the LexiconFigureFiles folder
lexicon_wavs <- list.files(lexicon_path, pattern = ".wav$")

# Double check that the files pulled are the selected files names above
lexicon_wavs

# Generate new image files of spectros using ggspectro. These should have correct text on x and y axis (numbers: time (s) frequency (KHz)), not necessarily titles. text also needs to be correct font size. 

# x label formatter function to control the number of decimal places for each axis text label
s_formatter <- function(x){
  # lab <- paste0(x, " s")
  lab <- sprintf("%0.2f", x)
}

# y label formatter function to control the aesthetics of the frequency axis text
khz_formatter <- function(y){
  lab <- paste0(y)
  # lab <- paste0(y, " kHz")
}

# Set color palette for spectrograms
gray_colors <- reverse.gray.colors.2(12)

# Next, iterate over audio files to generate 1 high quality spectrogram and image file per vocalization 

# w <- 1 # testing, freeze loop in the first iteration (To test, un-comment and run code inside of the curly brackets of the function). 

# invisible() silences the output of lapply() printed to the console (but not output from ggspectro())
invisible(lapply(X = 1:length(lexicon_wavs), FUN = function(w){
  
  # Read in the current audio file for this iteration, return a wave object
  tmp_wav <- tuneR::readWave(file.path(lexicon_path, lexicon_wavs[w]))
  # str(tmp_wav)
  
  # Use ggspectro to generate a spectrogram
  gg <- ggspectro(wave = tmp_wav, f = tmp_wav@samp.rate, ovlp = 90) +
    
    # Plot amplitude values or cells in the spectrogram. Interpolation needs to be TRUE and sit outside of the aes() call to smoothen the otherwise very pixelated appearance of the raster
    geom_raster(aes(fill = amplitude), hjust = 0, vjust = 0, interpolate = TRUE) +
    
    # Control the x-axis aesthetics
    scale_x_continuous(limits = c(0.08, 0.33), breaks = seq(0.1, 0.3, 0.05), labels = seq(0.1, 0.3, 0.05), expand = c(0, 0)) +
    
    # Control the y-axis aesthetics
    scale_y_continuous(limits = c(0, 9), breaks = seq(0, 8, 2), labels = seq(0, 8, 2), expand = c(0, 0)) +
    
    # We want spectrograms to be in grayscale
    # Change the values of limits to change how colors are assigned across amplitude bins
    scale_fill_gradientn(colours = gray_colors, name = "Amplitude \n (dB)", na.value = "transparent", limits = c(-35, 10)) +
    
    # Use the theme function above to modify the overall plot aesthetics
    theme(
      # Use element_blank() to remove grid lines
      panel.grid.major.y = element_blank(),
      panel.grid.major.x = element_blank(),
      panel.grid.minor = element_blank(),
      panel.background = element_rect(fill = "transparent"),
      panel.border = element_rect(linetype = "solid", fill = NA, color = "grey"),
      axis.line = element_line(linewidth = 0.15),
      legend.position = "none",
      plot.background = element_rect(fill = "white"),
      # Control the white space around the figure in the resulting image file
      plot.margin = unit(c(0, 0, 0.1, 0.1), "lines"), # top, right, bottom, left
      # Turn off the axis titles, which should remove titles for all 3 axes, including amplitude and the amplitude scale bar
      axis.title = element_blank(),
      # Control the size of the x and y-axis text 
      axis.text = element_text(size = 6.5, color = "black", vjust = 0),
      # Control the size of the axis tick lines
      axis.ticks = element_line(color = "black", linewidth = 0.15)
    )
  
  # When plots are created inside of an apply loop, you must save the plot as an abject and then explicitly print it so that the plot appears in the graphics device
  print(gg)
  
  # Once the plot is generated in the graphics device, you can save as an an image file on your computer using ggsave()
  # Substitute the ".wav" extension with the image file extension we will use, with gsub()
  # gsub(pattern = ".wav$", replace = ".jpeg", lexicon_wavs[w]) # uncomment to test inside of the function
  # The width and the height should be specified once you figure out a good size for spectrograms in the final composite figure
  ggsave(filename = file.path(figures_path, gsub(pattern = ".wav$", replace = ".jpeg", lexicon_wavs[w])), units = "in", width = 1.4, height = 1.25, dpi = 600)
}))

```

# Step 6: Adding colored borders to spectrogram image files by individual and group

Color palette should be from paletteer("nationalparkcolors::Arches"). There should be 6 colors with the hex codes: #A8CDECFF #F6955EFF #682C37FF #9B6981FF #7887A4FF #A89F8EFF. We will be using the first 3 colors to match the color scheme of the manuscript and the specific color labels used then generating the acoustic space plots. Color will indicate groups, hues within colors indicate individual. 

## Creating colored borders for the "group-specific" dataset. 
```{r eval=FALSE}

# Get colors for groups: we will the second and the third colors (orange and purple) for the groups in the main manuscript figures
cols <- paletteer::paletteer_d("nationalparkcolors::Arches")
# cols

# Generate a list of audio or image file names that will be used to add colored borders by group and individual within a group. This list has 4 vectors, 1 vector for each individual. We will need 2 group colors and 2 hues within each group color. We will append the pattern ".jpeg" for the file extension to the name of each vocalization in the loop below
img_list <- list(
  
  # Group 2, Individual 4
  c(
    "GroupMembership_Group2_Indiv4_Call1",
    "GroupMembership_Group2_Indiv4_Call2"
  ),
  # Group 2, Individual 6
  c(
    "GroupMembership_Group2_Indiv6_Call1",
    "GroupMembership_Group2_Indiv6_Call2"
  ),
  # Group 3, Individual 1
  c(
    "GroupMembership_Group3_Indiv1_Call3",
    "GroupMembership_Group3_Indiv1_Call4"
  ),
  # Group 3, Individual 4
  c(
    "GroupMembership_Group3_Indiv4_Call1",
    "GroupMembership_Group3_Indiv4_Call4"
  )
)

# This is a list with 4 elements, each element is a vector of the names of 2 vocalizations for 1 individual in a given group
str(img_list)

# We're using this list structure because colors correspond to individual information nested inside of group information. Therefore, we also need to specify colors in the same list structure, so we can map the names of vocalizations to the correct group color and individual level hue

# Set Group 2 individuals to the first color or cols[2] and Group 3 individuals to the second color or cols[3]. Hues per individual within a group should be set using the scales::alpha() function. This vector of colors is a different object than the list above, here there is 1 color specified per individual

# Using scales::alpha(cols[1], alpha = 0.25) to set a lighter color for the second individual per group did not work, it seems that image_border() doesn't discriminate between the original color and the transparent version. We used the rgb values of the original color per palette to make a darker version of each color so as to better discriminate unique individuals in the lexicon. These colors should also be added to acoustic space plots.

dark_col1 <- rgb(
    (col2rgb(cols[2]) - 80)[["red", 1]],
    (col2rgb(cols[2]) - 80)[["green", 1]],
    (col2rgb(cols[2]) - 80)[["blue", 1]],
    maxColorValue = 255
  )

light_col <- rgb(
    (col2rgb(cols[3]) + 80)[["red", 1]],
    (col2rgb(cols[3]) + 80)[["green", 1]],
    (col2rgb(cols[3]) + 80)[["blue", 1]],
    maxColorValue = 255
  )

cols_indivs <- c(
  
  # Group 2, Individual 4
  dark_col1,
  
  # Group 2, Individual 6
  scales::alpha(cols[2], alpha = 1),
  
  # Group 3, Individual 1
  scales::alpha(cols[3], alpha = 0.25),
  
  # Group 3, Individual 4
  light_col
)

cols_indivs

# Iterate over the list of vocalizations to map each vocalization back to the correct color and write out an updated image file with a colored border

# i <- 2 # testing, freeze loop in the first iteration (To test, un-comment and run code inside of the curly brackets of the function). 
# z <- 1 # testing, freeze loop in the first iteration (To test, un-comment and run code inside of the curly brackets of the function). 

# The outer loop with iterating variable i iterates over the length of img_list (4 individuals across 2 groups)
invisible(pblapply(1:length(img_list), function(i){
  
  # cols_indivs[i]
  
  # The inner loop with iterating variable z iterates over the length of vector i of img_list (2 vocalizations for 1 individual)
  lapply(1:length(img_list[[i]]), function(z){
    
    # Read in the original spectrogram image file
    # Inside file.path(), paste the correct file extension back to end of the vocalization name to read in the image file
    img <- magick::image_read(file.path(figures_path, paste(img_list[[i]][z], ".jpeg", sep = "")))
    
    # Add a colored border to the spectrogram object called "img" while making sure we're pulling the correct color and hue for this individual. Also specify the width of the border which appear to be in pixels, change those numbers passed to geometry to change the size of the border
    
    # Save the updated spectrogram with the colored border to a new spectrogram image file that has an updated name
    # magick::image_write(magick::image_border(image = img, color = cols_indivs[i], geometry = "10x10"), path = file.path(git_path, "Fig_2",  paste(img_list[[i]][z], "_border.jpeg", sep = "")), format = "jpeg")
    
    # saving thick versions of the figures for presentations
    magick::image_write(magick::image_border(image = img, color = cols_indivs[i], geometry = "20x20"), path = file.path(git_path, "Fig_2",  paste(img_list[[i]][z], "_border_thick.jpeg", sep = "")), format = "jpeg")
    
  })
  
}))

```

## Creating colored borders for the "individually distinctive" dataset. 
```{r eval=FALSE}

# Get colors for groups: we will the first two colors (blue and orange) for the groups in the main manuscript figures
cols <- paletteer::paletteer_d("nationalparkcolors::Arches")
cols

# Generate a list of audio or image file names that will be used to add colored borders by group and individual within a group. This list has 4 vectors, 1 vector for each individual. We will need 2 group colors and 2 hues within each group color. We will append the pattern ".jpeg" for the file extension to the name of each vocalization in the loop below
img_list <- list(
  
  # Group 1, Individual 1
  c(
    "IndividualIdentity_Group1_Indiv1_Call2",
    "IndividualIdentity_Group1_Indiv1_Call3"
  ),
  # Group 1, Individual 3
  c(
    "IndividualIdentity_Group1_Indiv3_Call1",
    "IndividualIdentity_Group1_Indiv3_Call2"
  ),
  # Group 2, Individual 1
  c(
    "IndividualIdentity_Group2_Indiv1_Call3",
    "IndividualIdentity_Group2_Indiv1_Call5"
  ),
  # Group 2, Individual 2
  c(
    "IndividualIdentity_Group2_Indiv2_Call1",
    "IndividualIdentity_Group2_Indiv2_Call2"
  )
)


# This is a list with 4 elements, each element is a vector of the names of 2 vocalizations for 1 individual in a given group
str(img_list)

# Set Group 1 to col[1] and group 2 to col [2] and then individuals to the same hues used above.

dark_col1 <- rgb(
    (col2rgb(cols[1]) - 80)[["red", 1]],
    (col2rgb(cols[1]) - 80)[["green", 1]],
    (col2rgb(cols[1]) - 80)[["blue", 1]],
    maxColorValue = 255
  )

dark_col2 <- rgb(
    (col2rgb(cols[2]) - 80)[["red", 1]],
    (col2rgb(cols[2]) - 80)[["green", 1]],
    (col2rgb(cols[2]) - 80)[["blue", 1]],
    maxColorValue = 255
  )

cols_indivs <- c(
  
  # Group 1, Individual 1
  dark_col1,
  
  # Group 1, Individual 3
  scales::alpha(cols[1], alpha = 1),
  
  # Group 2, Individual 1
  dark_col2,
  
  # Group 2, Individual 2
  scales::alpha(cols[2], alpha = 0.25)
)

cols_indivs

# Iterate over the list of vocalizations to map each vocalization back to the correct color and write out an updated image file with a colored border

# i <- 2 # testing the loop in the first iteration, individuals or vectors in the list
# z <- 1 # testing the loop in the first iteration, vocalizations or elements in each vector of the list

# The outer loop with iterating variable i iterates over the length of img_list (4 individuals across 2 groups)
invisible(pblapply(1:length(img_list), function(i){
  
  # The inner loop with iterating variable z iterates over the length of vector i of img_list (2 vocalizations for 1 individual)
  lapply(1:length(img_list[[i]]), function(z){
    
    # Read in the original spectrogram image file
    # Inside file.path(), paste the correct file extension back to end of the vocalization name to read in the image file
    img <- magick::image_read(file.path(figures_path, paste(img_list[[i]][z], ".jpeg", sep = "")))
    
    # Add a colored border to the spectrogram object called "img" while making sure we're pulling the correct color and hue for this individual. Also specify the width of the border which appear to be in pixels, change those numbers passed to geometry to change the size of the border
    
    # Save the updated spectrogram with the colored border to a new spectrogram image file that has an updated name
    # magick::image_write(magick::image_border(image = img, color = cols_indivs[i], geometry = "10x10"), path = file.path(git_path, "Fig_3", paste(img_list[[i]][z], "_border.jpeg", sep = "")), format = "jpeg")
        
    # saving thick versions of the figures for presentations
    magick::image_write(magick::image_border(image = img, color = cols_indivs[i], geometry = "20x20"), path = file.path(git_path, "Fig_3",  paste(img_list[[i]][z], "_border_thick.jpeg", sep = "")), format = "jpeg")
  })
  
}))

```